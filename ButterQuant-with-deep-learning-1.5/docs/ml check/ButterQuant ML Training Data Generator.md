"""
ButterQuant ML Training Data Generator
å†å²å›æµ‹æ¨¡æ‹Ÿç”Ÿæˆè®­ç»ƒæ•°æ®

åŠŸèƒ½:
1. VIXåˆ†å±‚é‡‡æ · (ä½æ³¢/å¸¸æ€/é«˜æ³¢)
2. å†å²è´è¶ç­–ç•¥æ¨¡æ‹Ÿ (as-ofåˆ†æ)
3. ç®€åŒ–IV Proxyè®¡ç®—
4. åŠ¨æ€è¯„ä¼°æ—¶é—´ç‚¹ (DTE-5å¤©)
5. 4åˆ†ç±»æ ‡æ³¨

é¢„è®¡è€—æ—¶: 2-3å°æ—¶
è¾“å‡º: ml/training_data_deep.parquet
"""

import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta
from pathlib import Path
import logging
import random

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class HistoricalDataGenerator:
    """å†å²å›æµ‹æ•°æ®ç”Ÿæˆå™¨"""
    
    def __init__(self, output_dir: str = "ml"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # é‡‡æ ·é…ç½®
        self.sample_config = {
            'LOW_VOL': 2000,
            'NORMAL': 3000,
            'HIGH_VOL': 2000
        }
        
        # VIXé˜ˆå€¼
        self.vix_thresholds = {
            'LOW_VOL': (0, 15),
            'NORMAL': (15, 25),
            'HIGH_VOL': (25, 100)
        }
        
        # æ—¶é—´èŒƒå›´
        self.start_date = "2023-01-01"
        self.end_date = "2025-01-31"
        
    def download_vix_data(self) -> pd.DataFrame:
        """ä¸‹è½½VIXå†å²æ•°æ®"""
        logger.info("ğŸ“¥ ä¸‹è½½VIXå†å²æ•°æ®...")
        vix = yf.download("^VIX", start=self.start_date, end=self.end_date, progress=False)
        logger.info(f"âœ… è·å– {len(vix)} å¤©VIXæ•°æ®")
        return vix
    
    def stratified_sampling(self, vix_data: pd.DataFrame) -> dict:
        """åŸºäºVIXçš„åˆ†å±‚é‡‡æ ·"""
        logger.info("ğŸ² æ‰§è¡Œåˆ†å±‚é‡‡æ ·...")
        
        samples = {}
        for regime, (low, high) in self.vix_thresholds.items():
            mask = (vix_data['Close'] >= low) & (vix_data['Close'] < high)
            eligible_dates = vix_data[mask].index.tolist()
            
            n_days = self.sample_config[regime] // 50
            
            if len(eligible_dates) < n_days:
                logger.warning(f"âš ï¸ {regime} å¯ç”¨æ—¥æœŸä¸è¶³: {len(eligible_dates)} < {n_days}")
                sampled = eligible_dates
            else:
                sampled = random.sample(eligible_dates, k=n_days)
            
            samples[regime] = sorted(sampled)
            logger.info(f"  {regime}: é‡‡æ · {len(sampled)} å¤© (VIX {low}-{high})")
        
        return samples
    
    def get_top_tickers(self, date: datetime, n: int = 50) -> list:
        """è·å–Top Næ ‡çš„"""
        ticker_pool = [
            'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'NVDA', 'TSLA', 'AMD', 'INTC', 'CRM',
            'JPM', 'BAC', 'WFC', 'GS', 'MS', 'C', 'BLK', 'SCHW',
            'JNJ', 'UNH', 'PFE', 'ABBV', 'TMO', 'MRK', 'LLY',
            'WMT', 'HD', 'NKE', 'MCD', 'COST', 'TGT', 'SBUX',
            'XOM', 'CVX', 'COP', 'SLB',
            'BA', 'CAT', 'GE', 'UPS', 'HON',
            'DIS', 'NFLX', 'V', 'MA', 'PYPL', 'SQ', 'UBER'
        ]
        return random.sample(ticker_pool, min(n, len(ticker_pool)))
    
    def get_iv_proxy(self, strike: float, spot: float, hv: float) -> float:
        """ç®€åŒ–ç‰ˆIVä»£ç†"""
        moneyness = strike / spot
        
        if moneyness < 0.95:
            multiplier = 1.25  # OTM Put
        elif moneyness > 1.05:
            multiplier = 1.10  # OTM Call
        else:
            multiplier = 1.15  # ATM
        
        return hv * multiplier
    
    def calculate_evaluation_date(self, analysis_date: datetime, dte: int) -> tuple:
        """åŠ¨æ€è®¡ç®—è¯„ä¼°æ—¥æœŸ"""
        if dte >= 30:
            days_to_eval = dte - 5
        else:
            days_to_eval = max(dte - 3, int(dte * 0.8))
        
        evaluation_date = analysis_date + timedelta(days=days_to_eval)
        return evaluation_date, days_to_eval
    
    def calculate_butterfly_roi(self, future_price, lower, center, upper, cost, max_profit):
        """è®¡ç®—è´è¶ç­–ç•¥ROI"""
        if lower <= future_price <= upper:
            if future_price <= center:
                payoff = max_profit * (future_price - lower) / (center - lower)
            else:
                payoff = max_profit * (upper - future_price) / (upper - center)
        else:
            payoff = -cost
        
        roi = payoff / cost if cost > 0 else -1.0
        return roi
    
    def classify_roi(self, roi: float) -> int:
        """ROIåˆ†ç±» (4åˆ†ç±»)"""
        if roi < -0.10:
            return 0  # äºæŸ
        elif roi < 0.05:
            return 1  # å¾®åˆ©
        elif roi < 0.15:
            return 2  # è‰¯å¥½
        else:
            return 3  # ä¼˜ç§€
    
    def simulate_butterfly_analysis(self, ticker: str, as_of_date: datetime) -> dict:
        """æ¨¡æ‹Ÿè´è¶ç­–ç•¥åˆ†æ"""
        try:
            # è·å–å†å²æ•°æ®
            hist = yf.download(ticker, end=as_of_date, period="90d", progress=False)
            
            if len(hist) < 30:
                return None
            
            spot = hist['Close'].iloc[-1]
            hv = hist['Close'].pct_change().std() * np.sqrt(252)
            
            # æ„é€ ç­–ç•¥
            dte = 30
            center_strike = round(spot, 0)
            wing_width = max(spot * 0.05, 5)
            
            lower_strike = center_strike - wing_width
            upper_strike = center_strike + wing_width
            
            # IV Proxy
            iv_lower = self.get_iv_proxy(lower_strike, spot, hv)
            iv_center = self.get_iv_proxy(center_strike, spot, hv)
            iv_upper = self.get_iv_proxy(upper_strike, spot, hv)
            
            # ç®€åŒ–å®šä»·
            def simple_option_price(strike, iv):
                intrinsic = max(strike - spot, 0)
                time_value = iv * np.sqrt(dte/365) * spot * 0.1
                return intrinsic + time_value
            
            price_lower = simple_option_price(lower_strike, iv_lower)
            price_center = simple_option_price(center_strike, iv_center)
            price_upper = simple_option_price(upper_strike, iv_upper)
            
            net_debit = price_lower - 2*price_center + price_upper
            max_profit = wing_width - net_debit
            
            # æ¨¡æ‹Ÿåˆ†æç»“æœ
            returns = hist['Close'].pct_change().dropna()
            forecast_price = spot * (1 + returns.mean() * dte)
            predicted_vol = returns.std() * np.sqrt(252)
            
            return {
                'ticker': ticker,
                'analysis_date': as_of_date,
                'spot_price': spot,
                'hv': hv,
                'butterfly': {
                    'lower_strike': lower_strike,
                    'center_strike': center_strike,
                    'upper_strike': upper_strike,
                    'net_debit': net_debit,
                    'max_profit': max_profit,
                    'max_loss': net_debit,
                    'profit_ratio': max_profit / net_debit if net_debit > 0 else 0,
                    'dte': dte
                },
                'fourier': {
                    'trend_slope': returns.mean() * 252,
                    'dominant_period_days': 21,
                    'period_strength': 0.3
                },
                'arima': {
                    'mean_forecast': forecast_price,
                    'confidence_interval_width': spot * 0.1
                },
                'garch': {
                    'predicted_vol': predicted_vol,
                    'current_iv': iv_center,
                    'vol_mispricing': (iv_center - predicted_vol) / predicted_vol,
                    'iv_percentile': 0.5
                },
                'greeks': {
                    'delta': 0.0,
                    'gamma': 0.05,
                    'vega': wing_width * 0.1,
                    'theta': -net_debit / dte
                }
            }
        except Exception as e:
            logger.warning(f"âš ï¸ {ticker} @ {as_of_date}: {e}")
            return None
    
    def generate_dataset(self) -> pd.DataFrame:
        """ä¸»æ•°æ®ç”Ÿæˆæµç¨‹"""
        # VIXé‡‡æ ·
        vix_data = self.download_vix_data()
        sampled_dates = self.stratified_sampling(vix_data)
        
        all_samples = []
        total_dates = sum(len(dates) for dates in sampled_dates.values())
        
        logger.info(f"ğŸš€ å¼€å§‹ç”Ÿæˆæ•°æ®: å…± {total_dates} å¤©")
        
        processed = 0
        for regime, dates in sampled_dates.items():
            logger.info(f"\nğŸ“Š å¤„ç† {regime} å¸‚åœº ({len(dates)} å¤©)")
            
            for date in dates:
                processed += 1
                logger.info(f"  [{processed}/{total_dates}] {date.date()}")
                
                tickers = self.get_top_tickers(date)
                
                for ticker in tickers:
                    try:
                        # æ¨¡æ‹Ÿåˆ†æ
                        analysis = self.simulate_butterfly_analysis(ticker, date)
                        if analysis is None:
                            continue
                        
                        # è®¡ç®—è¯„ä¼°æ—¥æœŸ
                        dte = analysis['butterfly']['dte']
                        eval_date, _ = self.calculate_evaluation_date(date, dte)
                        
                        # è·å–æœªæ¥ä»·æ ¼
                        future_data = yf.download(
                            ticker,
                            start=eval_date,
                            end=eval_date + timedelta(days=3),
                            progress=False
                        )
                        
                        if len(future_data) == 0:
                            continue
                        
                        future_price = future_data['Close'].iloc[0]
                        
                        # è®¡ç®—ROIå’Œæ ‡ç­¾
                        roi = self.calculate_butterfly_roi(
                            future_price,
                            analysis['butterfly']['lower_strike'],
                            analysis['butterfly']['center_strike'],
                            analysis['butterfly']['upper_strike'],
                            analysis['butterfly']['net_debit'],
                            analysis['butterfly']['max_profit']
                        )
                        
                        label = self.classify_roi(roi)
                        
                        # æå–ç‰¹å¾ (éœ€è¦å¯¼å…¥featuresæ¨¡å—)
                        from ml.features import extract_features_v2
                        features = extract_features_v2(analysis)
                        
                        # åˆå¹¶
                        sample = {
                            **features,
                            'label': label,
                            '_ticker': ticker,
                            '_date': date,
                            '_regime': regime,
                            '_debug_roi': roi
                        }
                        
                        all_samples.append(sample)
                        
                    except Exception as e:
                        logger.debug(f"    âš ï¸ {ticker}: {e}")
                        continue
                
                if processed % 10 == 0:
                    logger.info(f"  âœ… å·²æ”¶é›† {len(all_samples)} ä¸ªæ ·æœ¬")
        
        df = pd.DataFrame(all_samples)
        logger.info(f"\nâœ… æ•°æ®ç”Ÿæˆå®Œæˆ: {len(df)} ä¸ªæ ·æœ¬")
        
        return df
    
    def validate_dataset(self, df: pd.DataFrame):
        """æ•°æ®è´¨é‡éªŒè¯"""
        logger.info("\nğŸ” æ•°æ®è´¨é‡æ£€æŸ¥:")
        logger.info(f"  æ€»æ ·æœ¬æ•°: {len(df)}")
        
        # æ ‡ç­¾åˆ†å¸ƒ
        label_dist = df['label'].value_counts(normalize=True).sort_index()
        logger.info(f"  æ ‡ç­¾åˆ†å¸ƒ:")
        for label, pct in label_dist.items():
            logger.info(f"    Class {label}: {pct:.1%}")
        
        # ç¼ºå¤±å€¼
        missing = df.isnull().sum().sum()
        logger.info(f"  ç¼ºå¤±å€¼: {missing}")
        
        # ROIç»Ÿè®¡
        roi = df['_debug_roi'].values
        logger.info(f"\n  ROIç»Ÿè®¡:")
        logger.info(f"    å‡å€¼: {np.mean(roi):.2%}")
        logger.info(f"    ä¸­ä½æ•°: {np.median(roi):.2%}")
        logger.info(f"    P25: {np.percentile(roi, 25):.2%}")
        logger.info(f"    P75: {np.percentile(roi, 75):.2%}")
    
    def run(self):
        """æ‰§è¡Œå®Œæ•´æµç¨‹"""
        logger.info("=" * 70)
        logger.info("ğŸ¦‹ ButterQuant ML è®­ç»ƒæ•°æ®ç”Ÿæˆå™¨")
        logger.info("=" * 70)
        
        df = self.generate_dataset()
        self.validate_dataset(df)
        
        output_path = self.output_dir / "training_data_deep.parquet"
        df.to_parquet(output_path, index=False)
        logger.info(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜: {output_path}")
        
        return df


if __name__ == "__main__":
    generator = HistoricalDataGenerator()
    df = generator.run()