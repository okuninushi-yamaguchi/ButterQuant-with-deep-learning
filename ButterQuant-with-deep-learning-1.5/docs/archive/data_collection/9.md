"""
每日股票策略扫描脚本
在东京时间18:00启动，扫描Nasdaq 100 + S&P 500股票
"""

import time
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Set
import yfinance as yf

# 假设已有的分析器
from backend.analyzer import ButterflyAnalyzer


class DailyScanner:
    """每日定时扫描器"""
    
    def __init__(self, data_dir: str = "backend/data"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # 文件路径
        self.progress_file = self.data_dir / "scan_progress.txt"
        self.result_file = self.data_dir / "rankings_combined.json"
        self.log_file = self.data_dir / "scan_log.txt"
        
        # 配置日志
        self._setup_logging()
        
        # 扫描配置
        self.request_interval = 15  # 每15秒一次请求
        self.batch_checkpoint = 10  # 每10个股票保存一次
        
    def _setup_logging(self):
        """配置日志"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.log_file),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def load_tickers(self) -> List[str]:
        """
        加载并去重股票代码
        从nas100.md和sp500.md读取
        """
        tickers_set: Set[str] = set()
        
        # 读取Nasdaq 100
        nas100_file = Path("backend/data/nas100.md")
        if nas100_file.exists():
            with open(nas100_file, 'r') as f:
                content = f.read()
                # 假设格式: 每行一个ticker或者逗号分隔
                nas_tickers = [t.strip() for t in content.replace(',', '\n').split('\n') if t.strip()]
                tickers_set.update(nas_tickers)
                self.logger.info(f"Loaded {len(nas_tickers)} tickers from Nasdaq 100")
        
        # 读取S&P 500
        sp500_file = Path("backend/data/sp500.md")
        if sp500_file.exists():
            with open(sp500_file, 'r') as f:
                content = f.read()
                sp_tickers = [t.strip() for t in content.replace(',', '\n').split('\n') if t.strip()]
                before_count = len(tickers_set)
                tickers_set.update(sp_tickers)
                self.logger.info(f"Loaded {len(sp_tickers)} tickers from S&P 500")
                self.logger.info(f"Removed {len(sp_tickers) - (len(tickers_set) - before_count)} duplicates")
        
        tickers = sorted(list(tickers_set))
        self.logger.info(f"Total unique tickers: {len(tickers)}")
        return tickers
    
    def load_progress(self) -> Set[str]:
        """
        加载已完成的股票列表
        用于断点续传
        """
        if not self.progress_file.exists():
            return set()
        
        completed = set()
        with open(self.progress_file, 'r') as f:
            for line in f:
                if line.strip():
                    # 格式: TIMESTAMP|TICKER|STATUS
                    parts = line.strip().split('|')
                    if len(parts) >= 3 and parts[2] == 'SUCCESS':
                        completed.add(parts[1])
        
        self.logger.info(f"Loaded {len(completed)} completed tickers from progress file")
        return completed
    
    def save_progress(self, ticker: str, status: str, score: float = None):
        """
        保存进度到文件（追加模式）
        格式: TIMESTAMP|TICKER|STATUS|SCORE
        """
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        score_str = f"{score:.4f}" if score else "N/A"
        line = f"{timestamp}|{ticker}|{status}|{score_str}\n"
        
        with open(self.progress_file, 'a') as f:
            f.write(line)
    
    def analyze_ticker(self, ticker: str) -> Dict:
        """
        分析单个股票
        使用yfinance获取数据，然后调用ButterflyAnalyzer
        """
        try:
            self.logger.info(f"Analyzing {ticker}...")
            
            # 使用yfinance获取股票信息（验证股票有效性）
            stock = yf.Ticker(ticker)
            info = stock.info
            
            if not info or 'regularMarketPrice' not in info:
                self.logger.warning(f"{ticker}: No market data available")
                return None
            
            # 调用现有的分析器
            analysis_result = ButterflyAnalyzer.full_analysis(ticker)
            
            if not analysis_result:
                return None
            
            return {
                'ticker': ticker,
                'company_name': info.get('longName', ticker),
                'strategy_type': analysis_result.get('strategy_type', 'Unknown'),
                'score': analysis_result.get('score', 0),
                'market_price': info.get('regularMarketPrice', 0),
                'analysis_time': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"{ticker}: Analysis failed - {str(e)}")
            return None
    
    def scan_all(self):
        """
        主扫描流程
        """
        start_time = datetime.now()
        self.logger.info("=" * 60)
        self.logger.info(f"Daily scan started at {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        self.logger.info("=" * 60)
        
        # 加载股票列表
        tickers = self.load_tickers()
        
        # 加载已完成的股票（支持断点续传）
        completed = self.load_progress()
        remaining = [t for t in tickers if t not in completed]
        
        self.logger.info(f"Total: {len(tickers)}, Completed: {len(completed)}, Remaining: {len(remaining)}")
        
        if not remaining:
            self.logger.info("All tickers already scanned!")
            return
        
        # 开始扫描
        results = []
        success_count = 0
        failed_count = 0
        
        for i, ticker in enumerate(remaining, 1):
            try:
                # 分析股票
                result = self.analyze_ticker(ticker)
                
                if result:
                    results.append(result)
                    self.save_progress(ticker, 'SUCCESS', result['score'])
                    success_count += 1
                    self.logger.info(f"✓ {ticker}: {result['strategy_type']} (Score: {result['score']:.4f})")
                else:
                    self.save_progress(ticker, 'NO_DATA')
                    failed_count += 1
                    self.logger.warning(f"✗ {ticker}: No valid analysis result")
                
                # 每批次保存一次结果
                if len(results) % self.batch_checkpoint == 0:
                    self._save_intermediate_results(results)
                    self.logger.info(f"Checkpoint: Saved {len(results)} results")
                
                # 进度报告
                progress = (len(completed) + i) / len(tickers) * 100
                eta_seconds = ((time.time() - start_time.timestamp()) / i) * (len(remaining) - i)
                eta_minutes = int(eta_seconds / 60)
                self.logger.info(f"Progress: {progress:.1f}% ({i}/{len(remaining)}) - ETA: {eta_minutes} min")
                
            except Exception as e:
                self.logger.error(f"{ticker}: Unexpected error - {str(e)}")
                self.save_progress(ticker, 'ERROR')
                failed_count += 1
            
            # 等待15秒再继续（避免rate limit）
            if i < len(remaining):  # 最后一个不需要等待
                time.sleep(self.request_interval)
        
        # 保存最终结果
        self._save_final_results(results)
        
        # 统计信息
        end_time = datetime.now()
        duration = end_time - start_time
        
        self.logger.info("=" * 60)
        self.logger.info(f"Scan completed at {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        self.logger.info(f"Duration: {duration}")
        self.logger.info(f"Success: {success_count}, Failed: {failed_count}")
        self.logger.info(f"Results saved to: {self.result_file}")
        self.logger.info("=" * 60)
    
    def _save_intermediate_results(self, results: List[Dict]):
        """保存中间结果（临时文件）"""
        temp_file = self.data_dir / "rankings_combined.tmp.json"
        with open(temp_file, 'w') as f:
            json.dump(results, f, indent=2)
    
    def _save_final_results(self, results: List[Dict]):
        """
        保存最终结果
        按分数排序并保存
        """
        # 排序
        sorted_results = sorted(results, key=lambda x: x['score'], reverse=True)
        
        # 添加排名
        for rank, item in enumerate(sorted_results, 1):
            item['rank'] = rank
        
        # 保存完整结果
        output = {
            'last_updated': datetime.now().isoformat(),
            'total_stocks': len(sorted_results),
            'rankings': sorted_results
        }
        
        with open(self.result_file, 'w') as f:
            json.dump(output, f, indent=2)
        
        # 同时保存top 20（用于快速API响应）
        top20_file = self.data_dir / "rankings_top20.json"
        top20_output = {
            'last_updated': output['last_updated'],
            'total_stocks': output['total_stocks'],
            'rankings': sorted_results[:20]
        }
        with open(top20_file, 'w') as f:
            json.dump(top20_output, f, indent=2)
        
        self.logger.info(f"Saved {len(sorted_results)} ranked results")
        self.logger.info(f"Top 20 saved to: {top20_file}")
    
    def reset_progress(self):
        """重置进度（用于重新开始扫描）"""
        if self.progress_file.exists():
            self.progress_file.unlink()
            self.logger.info("Progress file reset")


# 命令行运行
if __name__ == "__main__":
    import sys
    
    scanner = DailyScanner()
    
    if len(sys.argv) > 1 and sys.argv[1] == '--reset':
        scanner.reset_progress()
        print("Progress reset. Run again without --reset to start scanning.")
    else:
        scanner.scan_all()