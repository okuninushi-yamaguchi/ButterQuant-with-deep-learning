# é˜¶æ®µ3ï¼šæ·±åº¦å­¦ä¹ é›†æˆæ–¹æ¡ˆ

## ğŸ¯ è®¾è®¡ç›®æ ‡

1. **æœ¬åœ°è®­ç»ƒ**ï¼šåˆ©ç”¨ä½ çš„ RTX 4060 è®­ç»ƒæ¨¡å‹
2. **äº‘ç«¯æ¨ç†**ï¼šéƒ¨ç½²è½»é‡çº§æ¨¡å‹åˆ°æœåŠ¡å™¨
3. **æ•°æ®å‡†å¤‡**ï¼šåˆ©ç”¨ç°æœ‰çš„ `market_research.db` æ•°æ®
4. **å¢é‡å­¦ä¹ **ï¼šæ¯å‘¨æ›´æ–°æ¨¡å‹ï¼ˆæ— éœ€é‡æ–°è®­ç»ƒï¼‰

---

## ğŸ“Š æ•°æ®æµæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      æ¯æ—¥æ‰«æï¼ˆdaily_scanner.pyï¼‰         â”‚
â”‚  - æ‰«æ Nasdaq 100 + S&P 500               â”‚
â”‚  - å†™å…¥ market_research.db                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ æ¯å¤©æ–°å¢ 23MB
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      TimescaleDB (PostgreSQL)              â”‚
â”‚  - æ—¶åºä¼˜åŒ–å­˜å‚¨                            â”‚
â”‚  - è‡ªåŠ¨æ•°æ®å‹ç¼©ï¼ˆå†å²æ•°æ®ï¼‰               â”‚
â”‚  - è¿ç»­èšåˆï¼ˆé¢„è®¡ç®—ç‰¹å¾ï¼‰                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ SQL æŸ¥è¯¢
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      æœ¬åœ°è®­ç»ƒç¯å¢ƒï¼ˆä½ çš„ç”µè„‘ï¼‰             â”‚
â”‚  â”œâ”€ æ•°æ®å¯¼å‡ºï¼šPostgreSQL â†’ Parquet        â”‚
â”‚  â”œâ”€ ç‰¹å¾å·¥ç¨‹ï¼šPandas + NumPy              â”‚
â”‚  â”œâ”€ æ¨¡å‹è®­ç»ƒï¼šPyTorch (RTX 4060)          â”‚
â”‚  â””â”€ æ¨¡å‹å¯¼å‡ºï¼šONNX / TorchScript          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ ä¸Šä¼ æ¨¡å‹
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      äº‘ç«¯æ¨ç†æœåŠ¡                          â”‚
â”‚  - ONNX Runtime (CPUæ¨ç†)                  â”‚
â”‚  - é›†æˆåˆ° Flask API                        â”‚
â”‚  - æ¯å‘¨è‡ªåŠ¨æ›´æ–°æ¨¡å‹                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¬ æ•°æ®å‡†å¤‡

### **1. æ•°æ®åº“è¿ç§»åˆ° TimescaleDB**
TimescaleDB æ˜¯ PostgreSQL çš„æ—¶åºæ•°æ®åº“æ‰©å±•ï¼Œç‰¹åˆ«é€‚åˆé‡‘èæ•°æ®ï¼š

```sql
-- åˆ›å»ºè¶…è¡¨ï¼ˆHypertableï¼‰
CREATE TABLE daily_metrics (
    time TIMESTAMPTZ NOT NULL,
    ticker TEXT NOT NULL,
    -- ... å…¶ä»–å­—æ®µï¼ˆä¸ä½ çš„ SQLite ç›¸åŒï¼‰
    PRIMARY KEY (time, ticker)
);

SELECT create_hypertable('daily_metrics', 'time');

-- è‡ªåŠ¨å‹ç¼©å†å²æ•°æ®ï¼ˆèŠ‚çœ 50-70% ç©ºé—´ï¼‰
ALTER TABLE daily_metrics SET (
  timescaledb.compress,
  timescaledb.compress_segmentby = 'ticker'
);

SELECT add_compression_policy('daily_metrics', INTERVAL '7 days');
```

**ä¼˜åŠ¿**ï¼š
- âœ… æŸ¥è¯¢é€Ÿåº¦æ¯” SQLite å¿« **10-100å€**
- âœ… è‡ªåŠ¨åˆ†åŒºï¼ˆæŒ‰æ—¶é—´ï¼‰
- âœ… æ”¯æŒè¿ç»­èšåˆï¼ˆé¢„è®¡ç®—ç‰¹å¾ï¼‰

---

### **2. æ•°æ®å¯¼å‡ºè„šæœ¬**
```python
# scripts/export_training_data.py
import pandas as pd
from sqlalchemy import create_engine

engine = create_engine('postgresql://user:pass@localhost/butterquant')

# å¯¼å‡ºæœ€è¿‘ 1 å¹´çš„æ•°æ®ç”¨äºè®­ç»ƒ
query = """
SELECT 
    time, ticker, current_price, 
    trend_direction, predicted_vol, 
    delta, gamma, vega, theta,
    total_score, recommendation,
    -- è®¡ç®—æ ‡ç­¾ï¼ˆ7å¤©åçš„å®é™…æ”¶ç›Šï¼‰
    LEAD(current_price, 7) OVER (PARTITION BY ticker ORDER BY time) 
        / current_price - 1 AS future_return_7d
FROM daily_metrics
WHERE time >= NOW() - INTERVAL '1 year'
  AND total_score > 50  -- åªç”¨é«˜è´¨é‡æ•°æ®è®­ç»ƒ
ORDER BY time
"""

df = pd.read_sql(query, engine)

# ä¿å­˜ä¸º Parquetï¼ˆå‹ç¼©ç‡é«˜ + è¯»å–å¿«ï¼‰
df.to_parquet('training_data.parquet', compression='snappy')
print(f"âœ… Exported {len(df)} records")
```

---

## ğŸ§  æ¨¡å‹è®¾è®¡

### **é¢„æµ‹ç›®æ ‡é€‰æ‹©**

æ ¹æ®ä½ çš„é‡åŒ–ç­–ç•¥ï¼Œæˆ‘å»ºè®® **3ä¸ªé¢„æµ‹ä»»åŠ¡**ï¼š

#### **ä»»åŠ¡ 1ï¼šç­–ç•¥æˆåŠŸç‡é¢„æµ‹ï¼ˆæ¨èä¼˜å…ˆåšï¼‰**
- **è¾“å…¥**ï¼šå½“å‰ Greeks + æ³¢åŠ¨ç‡ + å‚…ç«‹å¶ç‰¹å¾
- **è¾“å‡º**ï¼š7å¤©åç­–ç•¥æ˜¯å¦ç›ˆåˆ©ï¼ˆäºŒåˆ†ç±»ï¼‰
- **ç”¨é€”**ï¼šè¿‡æ»¤æ‰ä½æ¦‚ç‡æœºä¼š

```python
# æ•°æ®æ ‡ç­¾
df['label'] = (df['future_return_7d'].abs() < 0.02).astype(int)  # æ¨ªç›˜ = 1
```

#### **ä»»åŠ¡ 2ï¼šæ³¢åŠ¨ç‡é¢„æµ‹ï¼ˆä¸­æœŸï¼‰**
- **è¾“å…¥**ï¼šå†å²æ³¢åŠ¨ç‡åºåˆ— + GARCH é¢„æµ‹
- **è¾“å‡º**ï¼šæœªæ¥ 7 å¤©çš„å®é™…æ³¢åŠ¨ç‡
- **ç”¨é€”**ï¼šæ£€æµ‹ GARCH æ¨¡å‹è¯¯å·®ï¼Œä¼˜åŒ– IV é”™è¯¯å®šä»·

#### **ä»»åŠ¡ 3ï¼šä»·æ ¼æ–¹å‘é¢„æµ‹ï¼ˆé•¿æœŸï¼‰**
- **è¾“å…¥**ï¼šå¤šå› å­ç‰¹å¾
- **è¾“å‡º**ï¼šä¸Šæ¶¨/æ¨ªç›˜/ä¸‹è·Œï¼ˆä¸‰åˆ†ç±»ï¼‰
- **ç”¨é€”**ï¼šé€‰æ‹© Call/Put/Iron è´è¶

---

### **æ¨¡å‹æ¶æ„ï¼ˆPyTorchï¼‰**

```python
# models/strategy_predictor.py
import torch
import torch.nn as nn

class ButterflyNet(nn.Module):
    """è´è¶ç­–ç•¥é¢„æµ‹æ¨¡å‹"""
    
    def __init__(self, input_dim=20, hidden_dim=128):
        super().__init__()
        
        # ç‰¹å¾æå–
        self.feature_net = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3),
            
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.BatchNorm1d(hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.2),
        )
        
        # åˆ†ç±»å¤´
        self.classifier = nn.Linear(hidden_dim // 2, 2)  # ç›ˆåˆ©/äºæŸ
        
    def forward(self, x):
        features = self.feature_net(x)
        logits = self.classifier(features)
        return logits

# è®­ç»ƒè„šæœ¬
def train_model(train_loader, val_loader, epochs=50):
    model = ButterflyNet(input_dim=20).cuda()
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)
    criterion = nn.CrossEntropyLoss()
    
    best_val_acc = 0
    for epoch in range(epochs):
        model.train()
        for batch_x, batch_y in train_loader:
            batch_x, batch_y = batch_x.cuda(), batch_y.cuda()
            
            optimizer.zero_grad()
            logits = model(batch_x)
            loss = criterion(logits, batch_y)
            loss.backward()
            optimizer.step()
        
        # éªŒè¯
        val_acc = evaluate(model, val_loader)
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save(model.state_dict(), 'best_model.pth')
    
    return model
```

---

### **ç‰¹å¾å·¥ç¨‹**

```python
# scripts/feature_engineering.py
import pandas as pd
import numpy as np

def engineer_features(df):
    """ç”Ÿæˆè®­ç»ƒç‰¹å¾"""
    features = []
    
    # 1. Greeks å½’ä¸€åŒ–
    features.extend([
        df['delta'] / df['current_price'],
        df['gamma'] / df['current_price']**2,
        df['vega'] / 100,  # IV å•ä½è½¬æ¢
        df['theta'] / df['current_price']
    ])
    
    # 2. æ³¢åŠ¨ç‡ç‰¹å¾
    features.extend([
        df['predicted_vol'],
        df['current_iv'],
        df['vol_mispricing'],
        df['iv_percentile']
    ])
    
    # 3. å‚…ç«‹å¶ç‰¹å¾
    features.extend([
        (df['trend_direction'] == 'UPTREND').astype(int),
        df['trend_slope'],
        df['dominant_period']
    ])
    
    # 4. æ—¶åºç‰¹å¾ï¼ˆæ»šåŠ¨ç»Ÿè®¡ï¼‰
    df['price_ma7'] = df.groupby('ticker')['current_price'].transform(
        lambda x: x.rolling(7).mean()
    )
    df['price_std7'] = df.groupby('ticker')['current_price'].transform(
        lambda x: x.rolling(7).std()
    )
    features.extend([
        df['current_price'] / df['price_ma7'],
        df['price_std7'] / df['price_ma7']
    ])
    
    # 5. ç­–ç•¥æŒ‡æ ‡
    features.extend([
        df['profit_ratio'],
        df['prob_profit'],
        df['total_score'] / 100
    ])
    
    return pd.DataFrame(features).T
```

---

## ğŸš€ éƒ¨ç½²æµç¨‹

### **1. æ¨¡å‹è½¬æ¢ï¼ˆONNXï¼‰**
```python
# scripts/export_onnx.py
import torch
from models.strategy_predictor import ButterflyNet

model = ButterflyNet(input_dim=20)
model.load_state_dict(torch.load('best_model.pth'))
model.eval()

dummy_input = torch.randn(1, 20)
torch.onnx.export(
    model,
    dummy_input,
    'butterfly_model.onnx',
    input_names=['features'],
    output_names=['logits'],
    dynamic_axes={'features': {0: 'batch_size'}}
)
```

---

### **2. é›†æˆåˆ° Flask**
```python
# backend/ml_inference.py
import onnxruntime as ort
import numpy as np

class MLPredictor:
    def __init__(self, model_path='models/butterfly_model.onnx'):
        self.session = ort.InferenceSession(model_path)
        
    def predict_success(self, features):
        """é¢„æµ‹ç­–ç•¥æˆåŠŸæ¦‚ç‡"""
        # features: [delta, gamma, vega, theta, ...]
        input_array = np.array(features, dtype=np.float32).reshape(1, -1)
        
        outputs = self.session.run(None, {'features': input_array})
        logits = outputs[0]
        
        # Softmax
        probs = np.exp(logits) / np.exp(logits).sum()
        return probs[0][1]  # ç›ˆåˆ©æ¦‚ç‡

# åœ¨ analyzer.py ä¸­è°ƒç”¨
ml_predictor = MLPredictor()

def full_analysis(ticker):
    # ... åŸæœ‰é€»è¾‘ ...
    
    # æå–ç‰¹å¾
    features = [
        result['greeks']['delta'],
        result['greeks']['gamma'],
        # ... å…¶ä»–ç‰¹å¾
    ]
    
    # ML é¢„æµ‹
    ml_score = ml_predictor.predict_success(features)
    
    # èåˆåˆ°æ€»åˆ†
    result['ml_success_prob'] = ml_score
    result['total_score'] = result['total_score'] * 0.7 + ml_score * 100 * 0.3
    
    return result
```

---

## ğŸ“… è®­ç»ƒè®¡åˆ’

### **åˆæœŸï¼ˆç¬¬1-2å‘¨ï¼‰**
- [x] å¯¼å‡º 6ä¸ªæœˆçš„å†å²æ•°æ®ï¼ˆçº¦ 4GBï¼‰
- [x] ç‰¹å¾å·¥ç¨‹ + æ•°æ®æ¸…æ´—
- [x] è®­ç»ƒåŸºç¡€æ¨¡å‹ï¼ˆBinary Classificationï¼‰

### **ä¸­æœŸï¼ˆç¬¬3-8å‘¨ï¼‰**
- [ ] è¶…å‚æ•°è°ƒä¼˜ï¼ˆå­¦ä¹ ç‡ã€Dropoutã€ç½‘ç»œæ·±åº¦ï¼‰
- [ ] äº¤å‰éªŒè¯ï¼ˆæŒ‰æ—¶é—´åˆ†å‰²ï¼‰
- [ ] æ¨¡å‹é›†æˆï¼ˆXGBoost + PyTorch èåˆï¼‰

### **é•¿æœŸï¼ˆ3ä¸ªæœˆåï¼‰**
- [ ] Transformer æ¶æ„ï¼ˆå¤„ç†æ—¶åºä¾èµ–ï¼‰
- [ ] å¼ºåŒ–å­¦ä¹ ï¼ˆç«¯åˆ°ç«¯ç­–ç•¥ä¼˜åŒ–ï¼‰
- [ ] AutoMLï¼ˆè‡ªåŠ¨ç‰¹å¾é€‰æ‹©ï¼‰

---

## ğŸ’° æˆæœ¬ä¼°ç®—

- **è®­ç»ƒæˆæœ¬**ï¼šÂ¥0ï¼ˆä½ çš„ RTX 4060ï¼Œç”µè´¹å¯å¿½ç•¥ï¼‰
- **äº‘ç«¯æ¨ç†**ï¼šÂ¥50/æœˆï¼ˆONNX Runtimeï¼ŒCPU è¶³å¤Ÿï¼‰
- **æ•°æ®å­˜å‚¨**ï¼šÂ¥100/æœˆï¼ˆPostgreSQL + TimescaleDBï¼‰

**æ€»è®¡**ï¼šÂ¥150/æœˆï¼ˆå¢é‡æˆæœ¬ï¼‰

---

## ğŸ¯ é¢„æœŸæ•ˆæœ

æ ¹æ®ç±»ä¼¼é¡¹ç›®ç»éªŒï¼š
- **ç­–ç•¥æˆåŠŸç‡é¢„æµ‹**ï¼šå‡†ç¡®ç‡ 60-70%ï¼ˆéšæœºæ˜¯ 50%ï¼‰
- **æ³¢åŠ¨ç‡é¢„æµ‹**ï¼šRMSE æ¯” GARCH é™ä½ 15-25%
- **æ€»åˆ†æå‡**ï¼šé«˜åˆ†æœºä¼šçš„å®é™…ç›ˆåˆ©ç‡æé«˜ 10-20%

**å…³é”®**ï¼šæ·±åº¦å­¦ä¹ ä¸æ˜¯ä¸‡èƒ½è¯ï¼Œå®ƒæ˜¯å¯¹ä¼ ç»Ÿé‡åŒ–æ¨¡å‹çš„**å¢å¼º**ï¼Œä¸æ˜¯æ›¿ä»£ã€‚
