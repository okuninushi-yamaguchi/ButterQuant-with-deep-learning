# backend/database.py - 优化版

import sqlite3
import json
from datetime import datetime
from contextlib import contextmanager
import threading
import logging

logger = logging.getLogger(__name__)

class DatabaseManager:
    """数据库管理器（线程安全 + 连接池）"""
    
    def __init__(self, db_path='data/history.db', research_db_path='data/market_research.db'):
        self.db_path = db_path
        self.research_db_path = research_db_path
        self._local = threading.local()  # 每个线程独立连接
        
        # 初始化数据库
        self.init_db()
        self.create_indexes()
    
    @contextmanager
    def get_connection(self, db_path=None):
        """获取数据库连接（上下文管理器）"""
        db_path = db_path or self.db_path
        
        # 每个线程维护独立连接
        if not hasattr(self._local, 'conn') or self._local.conn is None:
            self._local.conn = sqlite3.connect(
                db_path,
                check_same_thread=False,
                timeout=30.0  # 30秒超时
            )
            self._local.conn.row_factory = sqlite3.Row  # 返回字典式结果
            
            # 性能优化配置
            self._local.conn.execute("PRAGMA journal_mode=WAL")  # Write-Ahead Logging
            self._local.conn.execute("PRAGMA synchronous=NORMAL")  # 平衡安全与性能
            self._local.conn.execute("PRAGMA cache_size=-64000")  # 64MB 缓存
            self._local.conn.execute("PRAGMA temp_store=MEMORY")  # 临时表放内存
        
        try:
            yield self._local.conn
        except Exception as e:
            self._local.conn.rollback()
            logger.error(f"Database error: {e}")
            raise
        else:
            self._local.conn.commit()
    
    def init_db(self):
        """初始化数据库表"""
        # 主历史表
        with self.get_connection() as conn:
            conn.execute('''
                CREATE TABLE IF NOT EXISTS analysis_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    ticker TEXT NOT NULL,
                    analysis_date TEXT NOT NULL,
                    total_score REAL,
                    butterfly_type TEXT,
                    recommendation TEXT,
                    full_result TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
        
        # 深度分析表
        with self.get_connection(self.research_db_path) as conn:
            conn.execute('''
                CREATE TABLE IF NOT EXISTS daily_metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    ticker TEXT NOT NULL,
                    analysis_date TEXT NOT NULL,
                    current_price REAL,
                    
                    -- 傅立叶分析
                    trend_direction TEXT,
                    trend_slope REAL,
                    dominant_period REAL,
                    
                    -- ARIMA 预测
                    predicted_price REAL,
                    prediction_lower REAL,
                    prediction_upper REAL,
                    price_stability REAL,
                    
                    -- GARCH 波动率
                    predicted_vol REAL,
                    current_iv REAL,
                    vol_mispricing REAL,
                    iv_percentile REAL,
                    
                    -- Greeks
                    delta REAL,
                    gamma REAL,
                    vega REAL,
                    theta REAL,
                    
                    -- 策略指标
                    butterfly_type TEXT,
                    max_profit REAL,
                    max_loss REAL,
                    profit_ratio REAL,
                    prob_profit REAL,
                    
                    -- 评分
                    total_score REAL,
                    recommendation TEXT,
                    
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    
                    -- 唯一约束（防止重复扫描）
                    UNIQUE(ticker, analysis_date)
                )
            ''')
    
    def create_indexes(self):
        """创建索引（提升查询性能）"""
        indexes = [
            # 主历史表索引
            ("idx_ticker", "analysis_history", "ticker"),
            ("idx_date", "analysis_history", "analysis_date"),
            ("idx_score", "analysis_history", "total_score"),
            ("idx_ticker_date", "analysis_history", "ticker, analysis_date"),
            
            # 深度分析表索引
            ("idx_research_ticker", "daily_metrics", "ticker"),
            ("idx_research_date", "daily_metrics", "analysis_date"),
            ("idx_research_score", "daily_metrics", "total_score"),
            ("idx_research_recommendation", "daily_metrics", "recommendation")
        ]
        
        for idx_name, table, columns in indexes:
            # 主历史表
            if table == "analysis_history":
                with self.get_connection() as conn:
                    try:
                        conn.execute(f"CREATE INDEX IF NOT EXISTS {idx_name} ON {table}({columns})")
                    except sqlite3.OperationalError:
                        pass  # 索引已存在
            
            # 深度分析表
            elif table == "daily_metrics":
                with self.get_connection(self.research_db_path) as conn:
                    try:
                        conn.execute(f"CREATE INDEX IF NOT EXISTS {idx_name} ON {table}({columns})")
                    except sqlite3.OperationalError:
                        pass
    
    def save_analysis(self, result):
        """保存分析结果到主历史表"""
        with self.get_connection() as conn:
            conn.execute('''
                INSERT INTO analysis_history (
                    ticker, analysis_date, total_score, 
                    butterfly_type, recommendation, full_result
                ) VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                result.get('ticker'),
                datetime.now().isoformat(),
                result.get('total_score'),
                result.get('butterfly_type'),
                result.get('recommendation'),
                json.dumps(result, ensure_ascii=False)
            ))
    
    def save_daily_metrics(self, ticker, result):
        """保存到深度分析表（展开的数据）"""
        try:
            with self.get_connection(self.research_db_path) as conn:
                # 提取所有字段
                fourier = result.get('fourier_analysis', {})
                arima = result.get('arima_forecast', {})
                garch = result.get('garch_volatility', {})
                greeks = result.get('greeks', {})
                strategy = result.get('butterfly_strategy', {})
                
                conn.execute('''
                    INSERT OR REPLACE INTO daily_metrics (
                        ticker, analysis_date, current_price,
                        trend_direction, trend_slope, dominant_period,
                        predicted_price, prediction_lower, prediction_upper, price_stability,
                        predicted_vol, current_iv, vol_mispricing, iv_percentile,
                        delta, gamma, vega, theta,
                        butterfly_type, max_profit, max_loss, profit_ratio, prob_profit,
                        total_score, recommendation
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    ticker,
                    datetime.now().date().isoformat(),
                    result.get('current_price'),
                    fourier.get('trend_direction'),
                    fourier.get('trend_slope'),
                    fourier.get('dominant_period'),
                    arima.get('predicted_price'),
                    arima.get('lower_bound'),
                    arima.get('upper_bound'),
                    arima.get('price_stability'),
                    garch.get('predicted_volatility'),
                    garch.get('current_iv'),
                    garch.get('iv_mispricing'),
                    garch.get('iv_percentile'),
                    greeks.get('delta'),
                    greeks.get('gamma'),
                    greeks.get('vega'),
                    greeks.get('theta'),
                    strategy.get('type'),
                    strategy.get('max_profit'),
                    strategy.get('max_loss'),
                    strategy.get('profit_loss_ratio'),
                    strategy.get('probability_of_profit'),
                    result.get('total_score'),
                    result.get('recommendation')
                ))
        except Exception as e:
            logger.error(f"Failed to save daily metrics for {ticker}: {e}")
    
    def get_top_opportunities(self, limit=20, min_score=70):
        """获取高分机会（用于仪表盘）"""
        with self.get_connection() as conn:
            cursor = conn.execute('''
                SELECT ticker, total_score, butterfly_type, recommendation, analysis_date
                FROM analysis_history
                WHERE total_score >= ?
                  AND DATE(analysis_date) = DATE('now')
                ORDER BY total_score DESC
                LIMIT ?
            ''', (min_score, limit))
            
            return [dict(row) for row in cursor.fetchall()]
    
    def get_history(self, ticker, days=30):
        """获取个股历史记录"""
        with self.get_connection() as conn:
            cursor = conn.execute('''
                SELECT *
                FROM analysis_history
                WHERE ticker = ?
                  AND analysis_date >= DATE('now', '-' || ? || ' days')
                ORDER BY analysis_date DESC
            ''', (ticker, days))
            
            return [dict(row) for row in cursor.fetchall()]
    
    def vacuum_database(self):
        """压缩数据库（定期维护）"""
        with self.get_connection() as conn:
            conn.execute("VACUUM")
        
        with self.get_connection(self.research_db_path) as conn:
            conn.execute("VACUUM")
    
    def close_all(self):
        """关闭所有连接"""
        if hasattr(self._local, 'conn') and self._local.conn:
            self._local.conn.close()
            self._local.conn = None


# ==================== 全局实例 ====================
db_manager = DatabaseManager()