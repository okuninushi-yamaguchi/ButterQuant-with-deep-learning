# ğŸ—ºï¸ ButterQuant å®æ–½è·¯çº¿å›¾

## ğŸ“… æ—¶é—´çº¿æ€»è§ˆ

```
ç°åœ¨         1å‘¨å        1ä¸ªæœˆå       3ä¸ªæœˆå       6ä¸ªæœˆå
 â”‚            â”‚            â”‚             â”‚             â”‚
 â–¼            â–¼            â–¼             â–¼             â–¼
é˜¶æ®µ0        é˜¶æ®µ1        é˜¶æ®µ2         é˜¶æ®µ2+        é˜¶æ®µ3
(å½“å‰)    (Redisç¼“å­˜)  (Celeryå¼‚æ­¥)  (ç›‘æ§ä¼˜åŒ–)   (æ·±åº¦å­¦ä¹ )

ç”¨æˆ·: 0     ç”¨æˆ·: 10-50  ç”¨æˆ·: 50-200  ç”¨æˆ·: 200-500 ç”¨æˆ·: 500+
æˆæœ¬: Â¥0    æˆæœ¬: Â¥0     æˆæœ¬: Â¥500    æˆæœ¬: Â¥800    æˆæœ¬: Â¥950
```

---

## ğŸš€ é˜¶æ®µ 1ï¼šæœ¬å‘¨å®Œæˆï¼ˆç«‹å³æ‰§è¡Œï¼‰

### **ç›®æ ‡**
- âœ… å“åº”é€Ÿåº¦æå‡ **50-150å€**ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
- âœ… å¹¶å‘èƒ½åŠ›æå‡ **50å€**
- âœ… é›¶æˆæœ¬ï¼ˆæœ¬åœ° Dockerï¼‰

### **æ ¸å¿ƒæ”¹åŠ¨**
1. æ·»åŠ  Redis ç¼“å­˜ï¼ˆ5åˆ†é’ŸTTLï¼‰
2. ä½¿ç”¨ Gunicorn + Geventï¼ˆ4 workersï¼‰
3. ä¼˜åŒ– SQLiteï¼ˆWAL æ¨¡å¼ + ç´¢å¼•ï¼‰

### **éƒ¨ç½²æ­¥éª¤**
```bash
# 1. å¤åˆ¶ Artifacts ä¸­çš„æ–‡ä»¶
cp artifacts/docker-compose.yml .
cp artifacts/backend/Dockerfile backend/
cp artifacts/backend/app.py backend/
cp artifacts/backend/database.py backend/

# 2. æ›´æ–°ä¾èµ–
echo "gunicorn==21.2.0
gevent==23.9.1
redis==5.0.1" >> backend/requirements.txt

# 3. å¯åŠ¨æœåŠ¡
docker-compose up -d

# 4. æµ‹è¯•
curl -X POST http://localhost:5000/api/analyze \
  -H "Content-Type: application/json" \
  -d '{"ticker": "AAPL"}'
```

### **éªŒæ”¶æ ‡å‡†**
- [ ] é¦–æ¬¡åˆ†æï¼š5-10ç§’
- [ ] é‡å¤è¯·æ±‚ï¼š< 100ms
- [ ] æ”¯æŒ 10+ å¹¶å‘ç”¨æˆ·
- [ ] Redis ç¼“å­˜å‘½ä¸­ç‡ > 50%

---

## ğŸ”¥ é˜¶æ®µ 2ï¼š1ä¸ªæœˆåï¼ˆç”¨æˆ·å¢é•¿è§¦å‘ï¼‰

### **è§¦å‘æ¡ä»¶**ï¼ˆæ»¡è¶³ä»»ä¸€ï¼‰
- æ—¥æ´»ç”¨æˆ· > 50
- ç”¨æˆ·æŠ±æ€¨å“åº”æ…¢
- æƒ³æ·»åŠ å®æ—¶ç›‘æ§åŠŸèƒ½

### **ç›®æ ‡**
- âœ… å¹¶å‘èƒ½åŠ›æå‡åˆ° **500-1000**
- âœ… ç”¨æˆ·ä½“éªŒè´¨çš„é£è·ƒï¼ˆå®æ—¶è¿›åº¦æ¡ï¼‰
- âœ… æ•°æ®åº“ç¨³å®šæ€§æå‡ï¼ˆPostgreSQLï¼‰

### **æ ¸å¿ƒæ”¹åŠ¨**
1. æ·»åŠ  Celery å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—
2. WebSocket å®æ—¶æ¨é€è¿›åº¦
3. SQLite â†’ PostgreSQL + TimescaleDB
4. Nginx åå‘ä»£ç†

### **æˆæœ¬**
- é˜¿é‡Œäº‘/è…¾è®¯äº‘ï¼šÂ¥500/æœˆ
- æ”¯æŒ 500-1000 æ—¥æ´»

---

## ğŸ“Š é˜¶æ®µ 2+ï¼š3ä¸ªæœˆåï¼ˆä¼˜åŒ–é˜¶æ®µï¼‰

### **ç›‘æ§ç³»ç»Ÿ**
```yaml
# docker-compose.yml æ–°å¢
prometheus:
  image: prom/prometheus
  volumes:
    - ./prometheus.yml:/etc/prometheus/prometheus.yml

grafana:
  image: grafana/grafana
  ports:
    - "3001:3000"
```

**ç›‘æ§æŒ‡æ ‡**ï¼š
- API å“åº”æ—¶é—´ï¼ˆP50/P95/P99ï¼‰
- ç¼“å­˜å‘½ä¸­ç‡
- Celery é˜Ÿåˆ—é•¿åº¦
- æ•°æ®åº“è¿æ¥æ± ä½¿ç”¨ç‡

### **è‡ªåŠ¨æ‰©å®¹**
å¦‚æœä½ ç”¨äº‘æœåŠ¡ï¼Œå¯ä»¥é…ç½®ï¼š
- CPU > 70% â†’ è‡ªåŠ¨å¢åŠ  Celery Worker
- é˜Ÿåˆ—ç§¯å‹ > 50 â†’ å‘é€å‘Šè­¦

---

## ğŸ§  é˜¶æ®µ 3ï¼š6ä¸ªæœˆåï¼ˆæ·±åº¦å­¦ä¹ ï¼‰

### **å‰ç½®æ¡ä»¶**
- âœ… ç´¯ç§¯ 6ä¸ªæœˆçš„äº¤æ˜“æ•°æ®ï¼ˆ~4GBï¼‰
- âœ… ç”¨æˆ·è§„æ¨¡ç¨³å®šï¼ˆ> 200 æ—¥æ´»ï¼‰
- âœ… ä½ å·²å­¦ä¹ å®Œ PyTorch åŸºç¡€

### **å®æ–½æ­¥éª¤**

#### **Week 1-2ï¼šæ•°æ®å‡†å¤‡**
```bash
# 1. è¿ç§»åˆ° TimescaleDB
python scripts/migrate_to_timescale.py

# 2. å¯¼å‡ºè®­ç»ƒæ•°æ®
python scripts/export_training_data.py
# è¾“å‡ºï¼štraining_data.parquet (çº¦ 2GB)

# 3. ç‰¹å¾å·¥ç¨‹
python scripts/feature_engineering.py
# è¾“å‡ºï¼šfeatures.npy, labels.npy
```

#### **Week 3-4ï¼šæ¨¡å‹è®­ç»ƒ**
```bash
# åœ¨ä½ çš„ç”µè„‘ä¸Šï¼ˆRTX 4060ï¼‰
python train.py \
  --data training_data.parquet \
  --epochs 50 \
  --batch-size 128 \
  --gpu 0

# é¢„è®¡è®­ç»ƒæ—¶é—´ï¼š2-4å°æ—¶
```

#### **Week 5ï¼šéƒ¨ç½²ä¸Šçº¿**
```bash
# 1. å¯¼å‡º ONNX
python export_onnx.py

# 2. ä¸Šä¼ åˆ°æœåŠ¡å™¨
scp butterfly_model.onnx user@server:/app/models/

# 3. æ›´æ–° Flask
# (é›†æˆ ml_inference.py)

# 4. é‡å¯æœåŠ¡
docker-compose restart backend
```

---

## ğŸ’° æˆæœ¬å¯¹æ¯”è¡¨

| é˜¶æ®µ | æ—¶é—´ | æœˆæˆæœ¬ | æ”¯æŒç”¨æˆ· | å“åº”æ—¶é—´ | å¼€å‘å·¥ä½œé‡ |
|------|------|--------|----------|----------|-----------|
| **0 (å½“å‰)** | - | Â¥0 | < 10 | 5-15ç§’ | - |
| **1 (Redis)** | 1å‘¨ | Â¥0 | 10-50 | < 100ms* | 5å°æ—¶ |
| **2 (Celery)** | 1æœˆ | Â¥500 | 50-500 | < 200ms | 3å¤© |
| **2+ (ç›‘æ§)** | 3æœˆ | Â¥800 | 200-1000 | < 150ms | 2å¤© |
| **3 (ML)** | 6æœˆ | Â¥950 | 500+ | < 100ms | 2å‘¨ |

*ç¼“å­˜å‘½ä¸­æ—¶

---

## ğŸ¯ å…³é”®å†³ç­–ç‚¹

### **Q1: ä»€ä¹ˆæ—¶å€™ä»é˜¶æ®µ1å‡çº§åˆ°é˜¶æ®µ2ï¼Ÿ**

**æ•°æ®é©±åŠ¨å†³ç­–**ï¼š
```python
# æ¯å‘¨æ£€æŸ¥ä»¥ä¸‹æŒ‡æ ‡
if (
    daily_active_users > 50 
    or redis_hit_rate < 40%  # ç¼“å­˜å‘½ä¸­ç‡ä½
    or avg_response_time > 3  # å¹³å‡å“åº”è¶…3ç§’
):
    print("ğŸš¨ å»ºè®®å‡çº§åˆ°é˜¶æ®µ2")
```

### **Q2: è¦ä¸è¦åšæ·±åº¦å­¦ä¹ ï¼Ÿ**

**å…ˆå›ç­” 3 ä¸ªé—®é¢˜**ï¼š
1. ç”¨æˆ·æ˜¯å¦åœ¨ä¹é¢„æµ‹å‡†ç¡®ç‡æå‡ 10%ï¼Ÿ
2. ä½ æ˜¯å¦æœ‰æ—¶é—´å­¦ä¹  PyTorchï¼Ÿ
3. æ•°æ®é‡æ˜¯å¦ > 6ä¸ªæœˆï¼ˆè‡³å°‘ 1000+ äº¤æ˜“æ¡ˆä¾‹ï¼‰ï¼Ÿ

**å¦‚æœ 3 ä¸ªéƒ½æ˜¯ "æ˜¯"** â†’ åšæ·±åº¦å­¦ä¹   
**å¦åˆ™** â†’ ç»§ç»­ä¼˜åŒ–ä¼ ç»Ÿé‡åŒ–æ¨¡å‹ï¼ˆARIMA/GARCHï¼‰

---

## ğŸ“ æ¯å‘¨æ£€æŸ¥æ¸…å•

### **é˜¶æ®µ 1 è¿è¡ŒæœŸé—´**
- [ ] å‘¨ä¸€ï¼šæŸ¥çœ‹ Redis ç¼“å­˜ç»Ÿè®¡ (`/api/cache/stats`)
- [ ] å‘¨ä¸‰ï¼šæ£€æŸ¥ SQLite æ•°æ®åº“å¤§å°ï¼ˆæ˜¯å¦éœ€è¦ VACUUMï¼‰
- [ ] å‘¨äº”ï¼šå¤‡ä»½æ•°æ®åº“ (`cp history.db history_backup.db`)
- [ ] å‘¨æ—¥ï¼šåˆ†æç”¨æˆ·è¡Œä¸ºï¼ˆå“ªäº›è‚¡ç¥¨æŸ¥è¯¢æœ€å¤šï¼Ÿï¼‰

### **é˜¶æ®µ 2 è¿è¡ŒæœŸé—´**
- [ ] æ¯å¤©ï¼šæŸ¥çœ‹ Celery é˜Ÿåˆ—é•¿åº¦ï¼ˆæ˜¯å¦ç§¯å‹ï¼Ÿï¼‰
- [ ] æ¯å‘¨ï¼šæ£€æŸ¥ PostgreSQL æ…¢æŸ¥è¯¢æ—¥å¿—
- [ ] æ¯æœˆï¼šä¼˜åŒ–æ•°æ®åº“ç´¢å¼•

### **é˜¶æ®µ 3 è¿è¡ŒæœŸé—´**
- [ ] æ¯å‘¨ï¼šæ›´æ–°æ¨¡å‹ï¼ˆå¢é‡è®­ç»ƒï¼‰
- [ ] æ¯æœˆï¼šè¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼ˆA/B æµ‹è¯•ï¼‰

---

## ğŸ é™„èµ ï¼šæ€§èƒ½åŸºå‡†æµ‹è¯•è„šæœ¬

```python
# scripts/benchmark.py
import requests
import time
import concurrent.futures

def test_single_request(ticker):
    """æµ‹è¯•å•æ¬¡è¯·æ±‚"""
    start = time.time()
    response = requests.post('http://localhost:5000/api/analyze', 
                            json={'ticker': ticker})
    elapsed = time.time() - start
    return elapsed

def test_concurrent(ticker, num_users=10):
    """æµ‹è¯•å¹¶å‘"""
    with concurrent.futures.ThreadPoolExecutor(max_workers=num_users) as executor:
        futures = [executor.submit(test_single_request, ticker) for _ in range(num_users)]
        times = [f.result() for f in futures]
    
    print(f"å¹¶å‘ {num_users} ç”¨æˆ·:")
    print(f"  å¹³å‡å“åº”æ—¶é—´: {sum(times)/len(times):.2f}s")
    print(f"  æœ€æ…¢è¯·æ±‚: {max(times):.2f}s")
    print(f"  æœ€å¿«è¯·æ±‚: {min(times):.2f}s")

if __name__ == '__main__':
    print("=== é˜¶æ®µ0 (ä¼˜åŒ–å‰) ===")
    print("é¦–æ¬¡è¯·æ±‚:", test_single_request('AAPL'), "ç§’")
    
    print("\n=== é˜¶æ®µ1 (Redisç¼“å­˜) ===")
    print("ç¼“å­˜å‘½ä¸­:", test_single_request('AAPL'), "ç§’")
    
    print("\n=== å¹¶å‘æµ‹è¯• ===")
    test_concurrent('TSLA', num_users=10)
```

---

## ğŸš¨ é£é™©æç¤º

### **æŠ€æœ¯é£é™©**
- **é˜¶æ®µ1** â†’ **é˜¶æ®µ2** è¿ç§»æ—¶ï¼Œéœ€è¦åœæœº 1-2 å°æ—¶ï¼ˆæ•°æ®åº“è¿ç§»ï¼‰
- **æ·±åº¦å­¦ä¹ **å¯èƒ½è¿‡æ‹Ÿåˆï¼Œéœ€è¦ä¸¥æ ¼çš„äº¤å‰éªŒè¯

### **æˆæœ¬é£é™©**
- å¦‚æœç”¨æˆ·å¢é•¿è¶…é¢„æœŸï¼Œäº‘æœåŠ¡å™¨è´¹ç”¨å¯èƒ½ç¿»å€
- **å»ºè®®**ï¼šè®¾ç½®è´¹ç”¨å‘Šè­¦ï¼ˆ> Â¥1000/æœˆè‡ªåŠ¨é€šçŸ¥ï¼‰

### **æ—¶é—´é£é™©**
- **é˜¶æ®µ2** çš„å®Œæ•´å®æ–½éœ€è¦ **3-5å¤©å…¨èŒå·¥ä½œ**
- **æ·±åº¦å­¦ä¹ **éœ€è¦ **2-4å‘¨å­¦ä¹  + å¼€å‘**

---

## âœ… ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **ä»Šå¤©**ï¼šéƒ¨ç½²é˜¶æ®µ1ï¼ˆDocker + Redisï¼‰
2. **æœ¬å‘¨**ï¼šè¿è¡Œ 7 å¤©ï¼Œæ”¶é›†æ€§èƒ½æ•°æ®
3. **ä¸‹å‘¨**ï¼šæ ¹æ®æ•°æ®å†³å®šæ˜¯å¦å¯åŠ¨é˜¶æ®µ2
4. **1ä¸ªæœˆå**ï¼šè¯„ä¼°æ˜¯å¦éœ€è¦äº‘æœåŠ¡å™¨

**æˆ‘ç°åœ¨å¯ä»¥å¸®ä½ **ï¼š
- ç”Ÿæˆå®Œæ•´çš„éƒ¨ç½²è„šæœ¬
- è§£ç­”ä»»ä½•æŠ€æœ¯ç–‘é—®
- ååŠ©æ’æŸ¥éƒ¨ç½²é—®é¢˜

éœ€è¦æˆ‘è¯¦ç»†è®²è§£å“ªä¸ªéƒ¨åˆ†ï¼ŸğŸš€