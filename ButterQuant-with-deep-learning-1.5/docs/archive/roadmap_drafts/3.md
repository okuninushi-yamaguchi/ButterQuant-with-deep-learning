# 阶段2：异步任务 + PostgreSQL（1个月后）

## 📊 架构演进

```
┌─────────────────────────────────────────────┐
│           用户浏览器                        │
│  - React 前端                               │
│  - WebSocket 连接（实时状态更新）          │
└──────────────┬──────────────────────────────┘
               │ HTTP/WS
┌──────────────▼──────────────────────────────┐
│           Nginx (反向代理)                  │
│  - 静态文件缓存                             │
│  - WebSocket 升级                           │
└──────────────┬──────────────────────────────┘
               │
┌──────────────▼──────────────────────────────┐
│      Flask API (Gunicorn + Gevent)          │
│  ├─ /api/analyze → 提交任务到 Celery       │
│  ├─ /api/task/<id> → 查询任务状态          │
│  └─ /ws → WebSocket 连接                    │
└──────────────┬──────────────────────────────┘
               │
         ┌─────┴─────┐
         ▼           ▼
    ┌────────┐  ┌──────────┐
    │ Redis  │  │ RabbitMQ │
    │ 缓存   │  │ 消息队列 │
    └────────┘  └─────┬────┘
                      │
         ┌────────────┴────────────┐
         ▼                         ▼
    ┌─────────┐             ┌─────────┐
    │ Celery  │             │ Celery  │
    │ Worker1 │  ...        │ Worker4 │
    │ (计算)  │             │ (计算)  │
    └────┬────┘             └────┬────┘
         │                       │
         └───────────┬───────────┘
                     ▼
              ┌─────────────┐
              │ PostgreSQL  │
              │ (持久化)    │
              └─────────────┘
```

---

## 🎯 核心优势

| 特性 | 阶段1 | 阶段2 | 提升 |
|------|-------|-------|------|
| **并发处理** | 50-100 | 500-1000 | 10倍 ✅ |
| **响应时间** | 5-10秒（阻塞） | < 200ms（异步） | 25倍 ✅ |
| **用户体验** | 等待白屏 | 实时进度条 | 质的飞跃 |
| **数据库** | SQLite（单文件） | PostgreSQL（企业级） | 稳定性 ↑↑ |
| **扩展性** | 单机 | 可横向扩展 | 无限 ✅ |

---

## 📦 技术栈

### **新增组件**
- **Celery 5.3**：分布式任务队列
- **RabbitMQ**：消息代理（比 Redis 更适合任务队列）
- **PostgreSQL 15**：关系型数据库
- **Flask-SocketIO**：WebSocket 支持
- **TimescaleDB**：时序数据库扩展（为深度学习准备）

### **Docker Compose 配置**
```yaml
version: '3.8'

services:
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./dist:/usr/share/nginx/html
    depends_on:
      - backend

  backend:
    build: ./backend
    command: gunicorn -w 4 -k geventwebsocket.gunicorn.workers.GeventWebSocketWorker -b 0.0.0.0:5000 app:app
    environment:
      - DATABASE_URL=postgresql://user:pass@postgres:5432/butterquant
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER=amqp://guest:guest@rabbitmq:5672//
    depends_on:
      - postgres
      - redis
      - rabbitmq

  celery_worker:
    build: ./backend
    command: celery -A tasks worker --loglevel=info --concurrency=4
    environment:
      - DATABASE_URL=postgresql://user:pass@postgres:5432/butterquant
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER=amqp://guest:guest@rabbitmq:5672//
    depends_on:
      - rabbitmq
      - postgres

  postgres:
    image: timescale/timescaledb:latest-pg15  # 内置 TimescaleDB
    environment:
      POSTGRES_DB: butterquant
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  rabbitmq:
    image: rabbitmq:3-management
    ports:
      - "5672:5672"   # AMQP
      - "15672:15672" # 管理界面
    environment:
      RABBITMQ_DEFAULT_USER: guest
      RABBITMQ_DEFAULT_PASS: guest

volumes:
  postgres_data:
```

---

## 🔧 实施步骤

### **1. 数据库迁移**
```python
# backend/migrate_to_postgres.py
import sqlite3
import psycopg2
from psycopg2.extras import execute_values

# 读取 SQLite
sqlite_conn = sqlite3.connect('data/history.db')
sqlite_cursor = sqlite_conn.cursor()
sqlite_cursor.execute("SELECT * FROM analysis_history")
rows = sqlite_cursor.fetchall()

# 写入 PostgreSQL
pg_conn = psycopg2.connect(
    "postgresql://user:pass@localhost:5432/butterquant"
)
pg_cursor = pg_conn.cursor()

# 创建表（带 TimescaleDB 优化）
pg_cursor.execute("""
    CREATE TABLE IF NOT EXISTS analysis_history (
        id SERIAL PRIMARY KEY,
        ticker TEXT NOT NULL,
        analysis_date TIMESTAMPTZ NOT NULL,
        total_score REAL,
        butterfly_type TEXT,
        recommendation TEXT,
        full_result JSONB,  -- 使用 JSONB 而非 TEXT
        created_at TIMESTAMPTZ DEFAULT NOW()
    );
    
    -- 转换为时序表（TimescaleDB）
    SELECT create_hypertable('analysis_history', 'analysis_date', if_not_exists => TRUE);
    
    -- 创建索引
    CREATE INDEX IF NOT EXISTS idx_ticker ON analysis_history(ticker);
    CREATE INDEX IF NOT EXISTS idx_score ON analysis_history(total_score DESC);
    CREATE INDEX IF NOT EXISTS idx_date ON analysis_history(analysis_date DESC);
""")

# 批量插入
execute_values(pg_cursor, """
    INSERT INTO analysis_history 
    (ticker, analysis_date, total_score, butterfly_type, recommendation, full_result)
    VALUES %s
""", rows)

pg_conn.commit()
print("✅ Migration completed!")
```

---

### **2. Celery 任务定义**
```python
# backend/tasks.py
from celery import Celery
import redis
import json
from analyzer import ButterflyAnalyzer
from database import db_manager

celery_app = Celery(
    'butterquant',
    broker='amqp://guest:guest@rabbitmq:5672//',
    backend='redis://redis:6379/1'
)

redis_client = redis.Redis(host='redis', port=6379, db=0, decode_responses=True)

@celery_app.task(bind=True, max_retries=3)
def analyze_ticker_async(self, ticker):
    """异步分析任务"""
    try:
        # 检查缓存
        cache_key = f"analysis:{ticker}"
        cached = redis_client.get(cache_key)
        if cached:
            return json.loads(cached)
        
        # 更新任务状态（WebSocket 会推送给前端）
        self.update_state(state='PROGRESS', meta={'status': 'Downloading data...'})
        
        # 执行分析
        analyzer = ButterflyAnalyzer(ticker)
        
        self.update_state(state='PROGRESS', meta={'status': 'Running ARIMA...'})
        result = analyzer.full_analysis()
        
        # 存入缓存 + 数据库
        redis_client.setex(cache_key, 300, json.dumps(result))
        db_manager.save_analysis(result)
        db_manager.save_daily_metrics(ticker, result)
        
        return result
        
    except Exception as e:
        self.update_state(state='FAILURE', meta={'error': str(e)})
        raise
```

---

### **3. WebSocket 实时推送**
```python
# backend/app.py 新增
from flask_socketio import SocketIO, emit

socketio = SocketIO(app, cors_allowed_origins="*")

@app.route('/api/analyze', methods=['POST'])
def analyze():
    ticker = request.json.get('ticker', 'AAPL').upper()
    
    # 提交异步任务
    task = analyze_ticker_async.delay(ticker)
    
    # 返回任务 ID
    return jsonify({
        'success': True,
        'task_id': task.id,
        'status': 'processing'
    })

@socketio.on('subscribe_task')
def handle_subscribe(data):
    """客户端订阅任务状态"""
    task_id = data['task_id']
    
    # 轮询任务状态并推送（实际应用中用 Celery Events）
    task = analyze_ticker_async.AsyncResult(task_id)
    
    while not task.ready():
        emit('task_update', {
            'task_id': task_id,
            'status': task.state,
            'meta': task.info
        })
        socketio.sleep(0.5)
    
    # 任务完成
    emit('task_complete', {
        'task_id': task_id,
        'result': task.result
    })
```

---

### **4. 前端集成 WebSocket**
```typescript
// src/hooks/useAsyncAnalysis.ts
import { io } from 'socket.io-client';

export function useAsyncAnalysis() {
  const [result, setResult] = useState(null);
  const [progress, setProgress] = useState('');
  const [loading, setLoading] = useState(false);

  const analyzeStock = async (ticker: string) => {
    setLoading(true);
    
    // 1. 提交任务
    const res = await fetch('/api/analyze', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ ticker })
    });
    const { task_id } = await res.json();
    
    // 2. 建立 WebSocket 连接
    const socket = io('http://localhost:5000');
    
    socket.emit('subscribe_task', { task_id });
    
    socket.on('task_update', (data) => {
      setProgress(data.meta.status); // "Running ARIMA..."
    });
    
    socket.on('task_complete', (data) => {
      setResult(data.result);
      setLoading(false);
      socket.disconnect();
    });
  };

  return { analyzeStock, result, progress, loading };
}
```

---

## 💰 成本估算

### **云服务器**（阿里云/腾讯云）
- **ECS 2核4G** × 1：¥150/月
- **PostgreSQL RDS** 20G：¥200/月
- **Redis 缓存** 1G：¥50/月
- **带宽** 5Mbps：¥100/月

**总计**：¥500/月，支持 **500-1000 日活**

---

## 🎯 何时升级到阶段2？

**触发条件**（满足任意一个）：
- ✅ 日活用户 > 50
- ✅ Redis 缓存命中率 < 40%（说明重复请求少）
- ✅ 用户抱怨"分析太慢"
- ✅ 你想添加"实时监控"功能

**我的建议**：先用阶段1运行 **1-2个月**，收集真实数据再决定。